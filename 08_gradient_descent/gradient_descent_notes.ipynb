{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Descent\n",
    "\n",
    "1) **Optimization** - refers to the task of either **minimizing** or **maximizing** some function $f(x)$ by altering $x$\n",
    "* What are we trying to accomplish in optimization?\n",
    "    1. Find the parameters of a model which maximize the likelihood of data\n",
    "    2. Find the parameters of a model which minimize a cost function\n",
    "* **Objective function** - any function for which we wish to find the minimum or maximum\n",
    "    * If we are minimizing it has several names: **cost function, loss function, error function**\n",
    "    * Cost function optimization examples:\n",
    "        * Example: Cost of quality of care associated with the total number of patients in an emergency\n",
    "        * Example: Interested in predicting profit at a business and there is some cost associated with producing the product\n",
    "    * Cost functions in models:\n",
    "        * $RSS$ for Linear Regression: $J(\\beta)=\\frac{1}{n}\\sum_{i=1}^n (h_{\\beta}(x_i)-y_i)^2$ for $\\hat{\\beta}=(X^TX)^{-1}X^Ty$\n",
    "            * $\\sum (y_i-\\beta^T x_i)^2$\n",
    "        * Log-likelihood for Logistic Regression: $J(\\theta)=\\frac{1}{n}ln(p(\\bar{y}|X;\\theta))=\\frac{1}{n}\\sum_{i=1}^n (y_i ln(h_\\theta(x_i))+(1-y_i)ln(1-h_{\\theta}(x_i)))$\n",
    "            * $\\sum y_i log(g(\\beta^Tx_i)+(1-y_i)log(1-g(B^Tx_i))$ where $g(z)=\\frac{1}{1+e^{-z}}$\n",
    "* Useful calculus notations:\n",
    "    * $\\frac{dy}{dx} \\rightarrow$ derivative of $y$ with respect to $x$\n",
    "    * $\\frac{\\partial y}{\\partial x} \\rightarrow$ partial derivative of $y$ with respect to $x$\n",
    "    * $\\triangledown_x y \\rightarrow$ gradient of $y$ with respect to $x$\n",
    "    * $\\triangledown_X y \\rightarrow$ matrix derivatives of $y$ with respect to $X$\n",
    "    * $\\triangledown_{\\text{X}}y \\rightarrow$ tensor containing derivatives of $y$ with respect to X\n",
    "        * tensors are geometric objects that describe linear relations between geometric vectors, scalars, and other tensors\n",
    "    * $\\frac{\\partial f}{\\partial x} \\rightarrow$ Jacobian matrix $J \\in \\mathbb{R}^n \\rightarrow \\mathbb{R}^m$\n",
    "    * $\\triangledown_x^2 f(x)$ or $H(f)(x) \\rightarrow$ the Hessian matrix (or second derivative) of $f$ at the input point $x$\n",
    "    * $\\int f(x)dx \\rightarrow$ definite integral over the entire domain of $x$\n",
    "    * $\\int_{\\mathbb{S}} f(x)dx \\rightarrow$ definite integral with respect to $x$ over the set $\\mathbb{S}$\n",
    "* Using the derivatives of a function can be used to follow a function to its minimum\n",
    "![grad_desc_deriv](gradient_descent_derivative.png)\n",
    "    * Suppose we have a function $y=f(x)$, where both $x$ and $y$ are real numbers. The derivative of this function is denoted as $f'(x)$ or as $\\frac{dy}{dx}$. In other words, it specifies how to scale a small change in the input in order to obtain the corresponding change in the output: $f(x+\\epsilon)\\approx f(x) + \\epsilon f'(x)$\n",
    "* **Batch Gradient Descent (BGD)**\n",
    "    * Intuition\n",
    "        * Explore a neighborhood of parameters\n",
    "        * Go in the direction of steepest descent\n",
    "    * Mathematical definition\n",
    "        * 1-dimension: $J(\\beta)=\\beta^2$\n",
    "            1. Minimize $f(x)$ or $J(\\beta)$\n",
    "            2. Calculate the direction of steepest descent: $\\frac{dJ}{d\\beta}$\n",
    "                * Move in the direction of $-\\triangledown f(x)$\n",
    "            3. Choose a learning rate/step size: $\\epsilon$ / $\\alpha$\n",
    "                ![grad_desc_steps](http://i.imgur.com/uqKsueE.jpg)\n",
    "                * If $\\alpha$ is too small, convergence takes a long time\n",
    "                * If $\\alpha$ is too big, can overshoot the minimum\n",
    "            4. Repeatedly update parameters: $\\beta^{t+1}=\\beta^t-\\epsilon \\frac{dJ}{d\\beta}(\\beta^t)$\n",
    "                * Update: $x=x-\\alpha \\triangledown f(x)$\n",
    "        * $n$-dimension: $J(\\beta)=\\beta^2$\n",
    "            1. Calculate the direction of steepest descent: $\\triangledown J= \\frac{\\partial J}{\\partial \\beta_1}\\hat{e}_1 + \\frac{\\partial J}{\\partial \\beta_2}\\hat{e}_2 + \\cdots + \\frac{\\partial J}{\\partial \\beta_n}\\hat{e}_n$\n",
    "                * $\\triangledown f(a) = (\\frac{\\partial f}{\\partial x_1}(a),\\cdots,\\frac{\\partial f}{\\partial x_n}(a))$\n",
    "                * $\\triangledown f(a)$ points in the direction of greatest increase of $f$ at $a$\n",
    "            2. Choose a learning rate: $\\epsilon$\n",
    "            3. Repeatedly update parameters: $\\vec{\\beta}^{t+1} = \\vec{\\beta}^t - \\epsilon \\triangledown J$\n",
    "    * **Gradient Ascent**\n",
    "        * To maximize $f$, we can minimize $-f$\n",
    "        * Still use almost the same algorithm but:\n",
    "            * Replace: $x = x - \\alpha \\triangledown f(x)$\n",
    "            * With: $x = x + \\alpha \\triangledown f(x)$\n",
    "    * **Convergence criteria:**\n",
    "        * When a set number of iterations is done (may not have converged)\n",
    "        * When the percent change is small enough: $\\frac{cost_{old}-cost_{new}}{cost_{old}}$\n",
    "        * When the cost function is flat enough: $|\\triangledown f|<\\epsilon$\n",
    "    * When to use gradient descent?\n",
    "        * When cost function are **differentiable**\n",
    "        * When there is only **one** global optimum\n",
    "        * Global optimum is guaranteed when the cost function is globally convex\n",
    "        * When features have **similar scales**\n",
    "        * When asymptotic answer is acceptable\n",
    "    * When is gradient descent bad?\n",
    "        * Memory constraints (data doesn't fit in memory)\n",
    "        * Takes long time to compute cost function over many rows (cpu constrained - cost function is a function of *all* data)\n",
    "        * \"Online\" setting (data keeps coming in / new data continuously)\n",
    "        * Only finds local extrema\n",
    "        * Poor performance without feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) **Stochastic Gradient Descent (True SGD)** - performs gradient descent for each training example in $x$ along with its corresponding $y$ / same as gradient descent except at each step compute the cost function by using just one observation\n",
    "* Example: for linear regression, compute $(y_i-\\beta^Tx_i)^2$ instead of $\\sum_i(y_i-\\beta^Tx_i)^2$\n",
    "* SGD Algorithm:\n",
    "    * Sample a data point without replacement\n",
    "    * For each data point, do a step of gradient descent: $\\beta \\rightarrow \\beta - \\epsilon \\triangledown J_i(\\beta)$\n",
    "* Expected direction is correct\n",
    "    * Cost function is expected cost per observation: $J(\\beta)=E[J_i(\\beta)]=\\sum_{i=1}^n \\frac{1}{n}J_i(\\beta)$\n",
    "    * The gradient and expected gradient are also the same: $\\triangledown J(\\beta)=E[\\triangledown J_i(\\beta)]=\\sum_{i=1}^n \\frac{1}{n}\\triangledown J_i(\\beta)$\n",
    "* Convergence criteria (can't just wait until a random jump is flat or doesn't improve the cost)\n",
    "    * Take a moving average of these criteria: $T_{old}\\rightarrow pT_{current} + (1-p)T_{old}$\n",
    "    * Cut off iterations\n",
    "* Pros and Cons of SGD:\n",
    "    * (+) Only requires one observation in memory at once\n",
    "    * (+) Converges faster on average than batch SGD\n",
    "    * (+) Can optimize over a changing cost function (e.g. online setting\n",
    "    * (-) Can oscillate around optimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Variants of Stochastic Gradient Descent (SGD)\n",
    "* **\"Online\" SGD** - uses each observation as it is collected / updates model by performing a gradient descent step each time a new observation is collected\n",
    "    * example: every time a new transaction occurs, update your fraud model with that transaction\n",
    "    * can optionally discard old observations\n",
    "* **\"Batch\" SGD** - normal or plain vanilla gradient descent that computes the gradient of the cost function with respective to $\\theta$ for the entire data set\n",
    "* **\"Minibatch\" SGD** - uses random subset of data / performs an update for every mini-batch of training examples\n",
    "    * if the entire dataset doesn't fit in memory, train on random subset in each iteration\n",
    "    * this is like the sample average of the gradient\n",
    "* Which variant of gradient descent algorithm to use?\n",
    "    * in practice, SGD is often preferred because it requires less memory and computation\n",
    "    * but small batches may reduce the variance of your steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) **Newton-Raphson Method** - (aka Newton's Method) optimization method similar to gradient descent except uses root-finding method applied to cost function's first derivative, $f'(x)$\n",
    "* Algorithm in 1-dimension:\n",
    "    * choose initial $x_0$\n",
    "    * while $f'(x)>\\epsilon: x_{i+1}=x_i-\\frac{f'(x_i)}{f''(x_i)}$\n",
    "* Algorithm in higher dimensions:\n",
    "    * $y_{i+1}=y_i-H(y_i)^{-1}\\triangledown f(y_i)$\n",
    "    * $H(a) = [\\frac{\\partial f}{\\partial x_i \\partial x_j}(a)]$ is the Hessian matrix (the matrix of the second partial derivatives at $a$)\n",
    "* What are issues with Newton's method?\n",
    "    * Hessian might be singular, or computation can be slow\n",
    "    * Can diverge with a bad starting guess\n",
    "* Gradient descent vs Newton's Method:\n",
    "\n",
    "|            | Gradient descent | Newton's Method |\n",
    "|------------:|:----------------:|:---------------:|\n",
    "| Simplicity | a bit less       | a bit more      |\n",
    "| Parameters | $\\alpha$         | none            |\n",
    "| Iterations | more             | less            |\n",
    "| n < 1000   | same             | same            |\n",
    "| n > 10000  | better           | worse           |\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
